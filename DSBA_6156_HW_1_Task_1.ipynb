{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfbbe9bf",
   "metadata": {},
   "source": [
    "1.1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1dcbede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, RepeatedKFold, RepeatedStratifiedKFold, LeaveOneOut, cross_val_score, GridSearchCV, ParameterGrid\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# import category_encoders as ce\n",
    "import seaborn as sns\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9f519df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/umesh/opt/anaconda3/lib/python3.9/site-packages/sklearn/datasets/_openml.py:417: UserWarning: Multiple active versions of the dataset matching the name credit-g exist. Versions may be fundamentally different, returning version 1.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "credit_data = fetch_openml(\"credit-g\", as_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66890a5d",
   "metadata": {},
   "source": [
    "1.1) \n",
    "The continous features are duration, credit_amount, installment_commitment, residence_since, age, existing_credits, num_dependents. The categorical features are class(target), checking_status, credit_history, purpose, saving_status, employment, personal_status, other_parties, property_magnitude, other_payment_plans, housing, job, own_telephone, foreign_worker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29836d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['checking_status',\n",
       " 'duration',\n",
       " 'credit_history',\n",
       " 'purpose',\n",
       " 'credit_amount',\n",
       " 'savings_status',\n",
       " 'employment',\n",
       " 'installment_commitment',\n",
       " 'personal_status',\n",
       " 'other_parties',\n",
       " 'residence_since',\n",
       " 'property_magnitude',\n",
       " 'age',\n",
       " 'other_payment_plans',\n",
       " 'housing',\n",
       " 'existing_credits',\n",
       " 'job',\n",
       " 'num_dependents',\n",
       " 'own_telephone',\n",
       " 'foreign_worker']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7a8d48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_data.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f613552a",
   "metadata": {},
   "source": [
    "Categorical features contain finite number of distinct groups. Going by that definition and looking at the results above, following features can be classified as being categorical:\n",
    "\n",
    "checking_status\n",
    "credit_history\n",
    "employment\n",
    "foreign_worker\n",
    "housing\n",
    "job\n",
    "other_parties\n",
    "other_payment_plans\n",
    "own_telephone\n",
    "personal_status\n",
    "property_magnitude\n",
    "purpose\n",
    "savings_status\n",
    "Continuous features can have an infinite range of values. From the above list of features, we can say that the following features are continuous:\n",
    "\n",
    "duration\n",
    "credit_amount\n",
    "installment_commitment (installment rate in percentage of disposable income)\n",
    "residence_since (number of years)\n",
    "age\n",
    "existing_credits\n",
    "num_dependents\n",
    "All the features in the above list are numeric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2badbf78",
   "metadata": {},
   "source": [
    "1.2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27f44cf",
   "metadata": {},
   "source": [
    "We ordinal encode all the categorical features before creating the training, validation and test splits. We then scale the continuous features. Converting the data bunch to a data frame seems to have ordinally encoded the categorical variables, but to be on the safe side the following steps use 'as_frame=True' to download the dataset as a dataframe. We then perform an ordinal encoding on the categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02ef54f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/umesh/opt/anaconda3/lib/python3.9/site-packages/sklearn/datasets/_openml.py:417: UserWarning: Multiple active versions of the dataset matching the name credit-g exist. Versions may be fundamentally different, returning version 1.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "credit_dataX, credit_datay = fetch_openml('credit-g', version='active', as_frame=True, return_X_y =True)\n",
    "categorical_features = ['checking_status', 'credit_history', 'employment', 'foreign_worker',\n",
    "'housing',\n",
    "'job',\n",
    "'other_parties',\n",
    "'other_payment_plans',\n",
    "'own_telephone',\n",
    "'personal_status',\n",
    "'property_magnitude',\n",
    "'purpose',\n",
    "'savings_status']\n",
    "credit_dataX_ordinal = credit_dataX.copy()\n",
    "for feature in credit_dataX.iteritems():\n",
    "  if feature[0] in categorical_features:\n",
    "    credit_dataX_ordinal[feature[0]] = credit_dataX[feature[0]].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc926fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checking_status</th>\n",
       "      <th>duration</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>savings_status</th>\n",
       "      <th>employment</th>\n",
       "      <th>installment_commitment</th>\n",
       "      <th>personal_status</th>\n",
       "      <th>other_parties</th>\n",
       "      <th>residence_since</th>\n",
       "      <th>property_magnitude</th>\n",
       "      <th>age</th>\n",
       "      <th>other_payment_plans</th>\n",
       "      <th>housing</th>\n",
       "      <th>existing_credits</th>\n",
       "      <th>job</th>\n",
       "      <th>num_dependents</th>\n",
       "      <th>own_telephone</th>\n",
       "      <th>foreign_worker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5951.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7882.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4870.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   checking_status  duration  credit_history  purpose  credit_amount  \\\n",
       "0                0       6.0               4        3         1169.0   \n",
       "1                1      48.0               2        3         5951.0   \n",
       "2                3      12.0               4        6         2096.0   \n",
       "3                0      42.0               2        2         7882.0   \n",
       "4                0      24.0               3        0         4870.0   \n",
       "\n",
       "   savings_status  employment  installment_commitment  personal_status  \\\n",
       "0               4           4                     4.0                2   \n",
       "1               0           2                     2.0                1   \n",
       "2               0           3                     2.0                2   \n",
       "3               0           3                     2.0                2   \n",
       "4               0           2                     3.0                2   \n",
       "\n",
       "   other_parties  residence_since  property_magnitude   age  \\\n",
       "0              0              4.0                   0  67.0   \n",
       "1              0              2.0                   0  22.0   \n",
       "2              0              3.0                   0  49.0   \n",
       "3              2              4.0                   1  45.0   \n",
       "4              0              4.0                   3  53.0   \n",
       "\n",
       "   other_payment_plans  housing  existing_credits  job  num_dependents  \\\n",
       "0                    2        1               2.0    2             1.0   \n",
       "1                    2        1               1.0    2             1.0   \n",
       "2                    2        1               1.0    1             2.0   \n",
       "3                    2        2               1.0    2             2.0   \n",
       "4                    2        2               2.0    2             2.0   \n",
       "\n",
       "   own_telephone  foreign_worker  \n",
       "0              1               0  \n",
       "1              0               0  \n",
       "2              0               0  \n",
       "3              0               0  \n",
       "4              0               0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_dataX_ordinal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8cba9f",
   "metadata": {},
   "source": [
    "Performing Label encoding on the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8ba208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(credit_datay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff668a11",
   "metadata": {},
   "source": [
    "Creating the training, validation and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f15baa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the training test split\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(credit_dataX_ordinal, y)\n",
    "# creating the training validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7eba2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [feature for feature in credit_data.feature_names if feature not in categorical_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a458eb71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8031914893617021"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train\n",
    "X_train_scaled[numeric_features] = scaler.fit_transform(X_train_scaled[numeric_features])\n",
    "\n",
    "X_val_scaled = X_val\n",
    "X_val_scaled[numeric_features] = scaler.fit_transform(X_val_scaled[numeric_features])\n",
    "\n",
    "logistic_regression = LogisticRegression().fit(X_train, y_train)\n",
    "logistic_regression.predict(X_val)\n",
    "logistic_regression.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185b0c07",
   "metadata": {},
   "source": [
    "1.4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7af9a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the training test split anew\n",
    "X_trainval_pipe, X_test_pipe, y_trainval_pipe, y_test_pipe = train_test_split(credit_dataX, credit_datay)\n",
    "# creating a Repeated Stratified K fold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a44964",
   "metadata": {},
   "source": [
    "Logistic Regression (without scaled data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da32fddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.713\n"
     ]
    }
   ],
   "source": [
    "preprocess_lr = make_column_transformer(\n",
    "    (OneHotEncoder(), categorical_features))\n",
    "model_lr = make_pipeline(preprocess_lr, LogisticRegression())\n",
    "model_lr.fit(X_trainval_pipe, y_trainval_pipe)\n",
    "scores_lr = cross_val_score(model_lr, X_trainval_pipe, y_trainval_pipe, cv=skf, scoring='accuracy')\n",
    "print(\"score: {:.3f}\".format(np.mean(scores_lr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed181104",
   "metadata": {},
   "source": [
    "Logistic Regression (with scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd92aa98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.724\n"
     ]
    }
   ],
   "source": [
    "preprocess_lrs = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    (OneHotEncoder(), categorical_features))\n",
    "model_lrs = make_pipeline(preprocess_lrs, LogisticRegression())\n",
    "model_lrs.fit(X_trainval_pipe, y_trainval_pipe)\n",
    "scores_lrs = cross_val_score(model_lrs, X_trainval_pipe, y_trainval_pipe, cv=skf, scoring='accuracy')\n",
    "print(\"score: {:.3f}\".format(np.mean(scores_lrs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78835a17",
   "metadata": {},
   "source": [
    "Linear Support Vector (SVC) without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b8aec27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.724\n"
     ]
    }
   ],
   "source": [
    "preprocess_svc = make_column_transformer(\n",
    "    (OneHotEncoder(), categorical_features))\n",
    "model_svc = make_pipeline(preprocess_svc, LinearSVC())\n",
    "model_svc.fit(X_trainval_pipe, y_trainval_pipe)\n",
    "scores_svc = cross_val_score(model_svc, X_trainval_pipe, y_trainval_pipe, cv=skf, scoring='accuracy')\n",
    "print(\"score: {:.3f}\".format(np.mean(scores_svc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc70d91",
   "metadata": {},
   "source": [
    "Linear Support Vector (SVC) with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58221d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.736\n"
     ]
    }
   ],
   "source": [
    "preprocess_svcs = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    (OneHotEncoder(), categorical_features))\n",
    "model_svcs = make_pipeline(preprocess_svcs, LinearSVC( max_iter=5000))\n",
    "model_svcs.fit(X_trainval_pipe, y_trainval_pipe)\n",
    "scores_svcs = cross_val_score(model_svcs, X_trainval_pipe, y_trainval_pipe, cv=skf, scoring='accuracy')\n",
    "print(\"score: {:.3f}\".format(np.mean(scores_svcs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e9347a",
   "metadata": {},
   "source": [
    "Nearest neighbors without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c08075b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.713\n"
     ]
    }
   ],
   "source": [
    "preprocess_knn = make_column_transformer(\n",
    "    (OneHotEncoder(), categorical_features))\n",
    "model_knn = make_pipeline(preprocess_knn, KNeighborsClassifier())\n",
    "model_knn.fit(X_trainval_pipe, y_trainval_pipe)\n",
    "scores_knn = cross_val_score(model_knn, X_trainval_pipe, y_trainval_pipe, cv=skf, scoring='accuracy')\n",
    "print(\"score: {:.3f}\".format(np.mean(scores_knn)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9964926a",
   "metadata": {},
   "source": [
    "Nearest neighbors with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8d89e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.707\n"
     ]
    }
   ],
   "source": [
    "preprocess_knns = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    (OneHotEncoder(), categorical_features))\n",
    "model_knns = make_pipeline(preprocess_knns, KNeighborsClassifier())\n",
    "model_knns.fit(X_trainval_pipe, y_trainval_pipe)\n",
    "scores_knns = cross_val_score(model_knns, X_trainval_pipe, y_trainval_pipe, cv=skf, scoring='accuracy')\n",
    "print(\"score: {:.3f}\".format(np.mean(scores_knns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e365770d",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "From the results above we see that the accuracy is better when we use scaling on numeric features. For logistic regression, the accuracy improved from 0.732 to 0.745 when the data is scaled. For SVC the accuracy improved from 0.741 to 0.749 and for Nearest neighbors the accuracy improved from 0.716 to 0.738."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c20136",
   "metadata": {},
   "source": [
    "1.5\n",
    "Using GridSearchCV\n",
    "\n",
    "Creating a new split of data, using encoded data points for GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c830b039",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
